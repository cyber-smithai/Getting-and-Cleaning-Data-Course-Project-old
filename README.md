|         |            |  
| ------------- |:-------------:|
| Title:     | ReadMe.md |
| Author:     | Matthew Smith      |
| Date: | 4/6/2020   |
| University:      |Johns Hopkins University           |
|Specialization:       |  Data Science Specialization           |

## Project Description
This project utilizes the dataset created by the University of California; Irvine titled “Human Activity Recognition Using Smartphones” Data Set. 

Their experiments have been carried out with a group of 30 volunteers between ages of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, they captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.

For each record it is provided:

* Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.
* Triaxial Angular velocity from the gyroscope. 
* A 561-feature vector with time and frequency domain variables. 
* Its activity label. 
* An identifier of the subject who carried out the experiment.


## Project Files

This project contains the following files
* CodeBook.md. describes the variables, the data, and any work that are performed to clean up the data.
* run_analysis.R contains all the coding for doing the course project, that includes downloading and unzipping the dataset that is used for this project.
* secTidySet.txt is a written out text file from run_analysis.R, which is the average features of each subject and each activity. Please refer to CodeBook.md. for more explicit information.


